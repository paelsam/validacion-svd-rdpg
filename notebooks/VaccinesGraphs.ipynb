{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bf1882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csc_matrix\n",
    "import re\n",
    "\n",
    "# Methods to calculate svd\n",
    "from numpy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a5e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import concurrent.futures as cf\n",
    "\n",
    "try:\n",
    "    from joblib import Parallel, delayed \n",
    "    _HAVE_JOBLIB = True\n",
    "except Exception:\n",
    "    _HAVE_JOBLIB = False\n",
    "\n",
    "# Computes the full SVD of matrix A and returns the top k singular values.\n",
    "def truncated_svd(A, k=None, include_u_v=False):\n",
    "    S = svd(A, compute_uv=False, full_matrices=False)\n",
    "    if k is None:\n",
    "        k = len(S)\n",
    "    S_k = S[:k]\n",
    "    if include_u_v:\n",
    "        U, _, Vh = svd(A, full_matrices=False)\n",
    "        return S_k, U[:, :k], Vh[:k, :]\n",
    "    return S_k\n",
    "\n",
    "\n",
    "# Computes the log-likelihood for a given q\n",
    "def compute_ll_for_q(sv: np.ndarray, p: int, q: int):\n",
    "    q = int(q)\n",
    "    S1 = sv[:q]\n",
    "    S2 = sv[q:]\n",
    "\n",
    "    if len(S2) == 0 or p <= 2:\n",
    "        return (q, float(-np.inf))\n",
    "\n",
    "    mu1 = np.mean(S1) if len(S1) else 0.0\n",
    "    mu2 = np.mean(S2) if len(S2) else 0.0\n",
    "\n",
    "    if len(S1) > 1:\n",
    "        s1_squared = np.var(S1, ddof=1)\n",
    "    else:\n",
    "        s1_squared = 0.0\n",
    "\n",
    "    if len(S2) > 1:\n",
    "        s2_squared = np.var(S2, ddof=1)\n",
    "    else:\n",
    "        s2_squared = 0.0\n",
    "\n",
    "    sigma2 = ((q - 1) * s1_squared + (p - q - 1) * s2_squared) / (p - 2)\n",
    "    if not np.isfinite(sigma2) or sigma2 <= 0:\n",
    "        return (q, float(-np.inf))\n",
    "\n",
    "    sigma = np.sqrt(sigma2)\n",
    "\n",
    "    ll = 0.0\n",
    "    if len(S1):\n",
    "        ll += float(np.sum(norm.logpdf(S1, mu1, sigma)))\n",
    "    if len(S2):\n",
    "        ll += float(np.sum(norm.logpdf(S2, mu2, sigma)))\n",
    "\n",
    "    return (q, ll)\n",
    "\n",
    "# Estimate the embedding dimension using the profile likelihood method\n",
    "def embedding_dimension(singular_values, k=None, n_jobs: int = -1):\n",
    "    \n",
    "    if k is None:\n",
    "        k = len(singular_values)\n",
    "\n",
    "    sv = np.array(singular_values[:k], dtype=float)\n",
    "    p = len(sv)\n",
    "\n",
    "    if p <= 2:\n",
    "        return 1\n",
    "\n",
    "    qs = list(range(1, p))\n",
    "\n",
    "    if n_jobs == 1:\n",
    "        best_ll = float(-np.inf)\n",
    "        d_hat = 1\n",
    "        for q in qs:\n",
    "            _, ll = compute_ll_for_q(sv, p, q)\n",
    "            if ll > best_ll:\n",
    "                best_ll = ll\n",
    "                d_hat = q\n",
    "        return d_hat\n",
    "\n",
    "    if _HAVE_JOBLIB:\n",
    "        results = Parallel(n_jobs=n_jobs, backend=\"loky\")(\n",
    "            delayed(compute_ll_for_q)(sv, p, q) for q in qs\n",
    "        )\n",
    "    else:\n",
    "        max_workers = None if n_jobs in (None, -1) else int(n_jobs)\n",
    "        func = partial(compute_ll_for_q, sv, p)\n",
    "        with cf.ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            results = list(ex.map(func, qs))\n",
    "\n",
    "    if not results:\n",
    "        return 1\n",
    "\n",
    "    best_q, _best_ll = max(results, key=lambda t: t[1]) \n",
    "    return int(best_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files loaded successfully.\n",
      "DATA COUNT BY YEAR\n",
      "\n",
      "Year 2020:\n",
      "  - Number of edges: 223099\n",
      "  - Columns: ['anonyme_Source', 'anonyme_Target', 'Weight']\n",
      "\n",
      "Year 2021:\n",
      "  - Number of edges: 75750\n",
      "  - Columns: ['anonyme_Source', 'anonyme_Target', 'Weight']\n",
      "\n",
      "Year 2022:\n",
      "  - Number of edges: 14604\n",
      "  - Columns: ['anonyme_Source', 'anonyme_Target', 'Weight']\n",
      "Setting weights to 1...\n",
      "\n",
      "Graphs successfully generated with NetworkX.\n",
      "Graph 2020 - Number of nodes: 113027, Number of edges: 222566\n",
      "Graph 2021 - Number of nodes: 18826, Number of edges: 40394\n",
      "Graph 2022 - Number of nodes: 3617, Number of edges: 7910\n"
     ]
    }
   ],
   "source": [
    "df_2020 = pd.read_csv('../data/Vaccines/EdgesSource_Target_W_year=2020.csv')\n",
    "df_2021 = pd.read_csv('../data/Vaccines/EdgesSource_Target_W_year=2021.csv')\n",
    "df_2022 = pd.read_csv('../data/Vaccines/EdgesSource_Target_W_year=2022.csv')\n",
    "\n",
    "print(\"CSV files loaded successfully.\")\n",
    "\n",
    "# Print number of edges in each dataset\n",
    "print(\"DATA COUNT BY YEAR\")\n",
    "print(f\"\\nYear 2020:\")\n",
    "print(f\"  - Number of edges: {len(df_2020)}\")\n",
    "print(f\"  - Columns: {list(df_2020.columns)}\")\n",
    "\n",
    "print(f\"\\nYear 2021:\")\n",
    "print(f\"  - Number of edges: {len(df_2021)}\")\n",
    "print(f\"  - Columns: {list(df_2021.columns)}\")\n",
    "\n",
    "print(f\"\\nYear 2022:\")\n",
    "print(f\"  - Number of edges: {len(df_2022)}\")\n",
    "print(f\"  - Columns: {list(df_2022.columns)}\")\n",
    "print(\"Setting weights to 1...\")\n",
    "\n",
    "if 'Weight' in df_2020.columns:\n",
    "    df_2020['Weight'] = 1\n",
    "if 'Weight' in df_2021.columns:\n",
    "    df_2021['Weight'] = 1\n",
    "if 'Weight' in df_2022.columns:\n",
    "    df_2022['Weight'] = 1\n",
    "    \n",
    "G_2020 = nx.from_pandas_edgelist(df_2020, source='anonyme_Source', target='anonyme_Target', edge_attr='Weight', create_using=nx.Graph())\n",
    "G_2021 = nx.from_pandas_edgelist(df_2021, source='anonyme_Source', target='anonyme_Target', edge_attr='Weight', create_using=nx.Graph())\n",
    "G_2022 = nx.from_pandas_edgelist(df_2022, source='anonyme_Source', target='anonyme_Target', edge_attr='Weight', create_using=nx.Graph())\n",
    "\n",
    "print(\"\\nGraphs successfully generated with NetworkX.\")\n",
    "print(f\"Graph 2020 - Number of nodes: {G_2020.number_of_nodes()}, Number of edges: {G_2020.number_of_edges()}\")\n",
    "print(f\"Graph 2021 - Number of nodes: {G_2021.number_of_nodes()}, Number of edges: {G_2021.number_of_edges()}\")\n",
    "print(f\"Graph 2022 - Number of nodes: {G_2022.number_of_nodes()}, Number of edges: {G_2022.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba826bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021...\n",
      "Comunities: 159\n",
      "Modularity: 0.8898859343845554\n",
      "Assortativity: 0.9661178079065924\n",
      "Density: 0.00022795746438094078\n",
      "Clustering Coefficient: 0.08671400822456832\n",
      "Embedding Dimension 2021: 2928\n",
      "\n",
      "2022...\n",
      "Comunities: 71\n",
      "Modularity: 0.8115474419072979\n",
      "Assortativity: 0.9433629800904899\n",
      "Density: 0.0012095659386231685\n",
      "Clustering Coefficient: 0.09014308488788474\n",
      "Embedding Dimension 2022: 658\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for year, G in zip([2021, 2022], [G_2021, G_2022]):\n",
    "    print(f\"\\n{year}...\")\n",
    "\n",
    "    communities = nx.community.louvain_communities(G)\n",
    "    partition = {node: idx for idx, community in enumerate(communities) for node in community}\n",
    "    nx.set_node_attributes(G, partition, \"community\")\n",
    "\n",
    "    modularity = nx.community.modularity(G, communities)\n",
    "    assortativity = nx.attribute_assortativity_coefficient(G, \"community\")\n",
    "    density = nx.density(G)\n",
    "    clustering_coefficient = nx.average_clustering(G)\n",
    "\n",
    "    print(f\"Comunities: {len(communities)}\")\n",
    "    print(f\"Modularity: {modularity}\")\n",
    "    print(f\"Assortativity: {assortativity}\")\n",
    "    print(f\"Density: {density}\")\n",
    "    print(f\"Clustering Coefficient: {clustering_coefficient}\")\n",
    "\n",
    "    if year == 2020:\n",
    "        k = 8000\n",
    "        A = nx.to_scipy_sparse_array(G, format='csr', dtype=float)\n",
    "        u, s, vt = svds(A, k=k, which='LM')\n",
    "        singular_values = sorted(s, reverse=True)\n",
    "        d_hat = embedding_dimension(singular_values)\n",
    "        metrics[year] = {\n",
    "            \"singular_values\": singular_values,\n",
    "            \"embedding_dimension\": d_hat,\n",
    "            \"modularity\": modularity,\n",
    "            \"assortativity\": assortativity,\n",
    "            \"density\": density,\n",
    "            \"clustering_coefficient\": clustering_coefficient\n",
    "        }\n",
    "        print(f\"Using sparse SVD for year {year} with k={k}\")\n",
    "        print(f\"Embedding Dimension {year}: {d_hat}\")\n",
    "    else:\n",
    "        A = nx.to_numpy_array(G, dtype=int )\n",
    "        singular_values = truncated_svd(A)\n",
    "        d_hat = embedding_dimension(singular_values)\n",
    "        metrics[year] = {\n",
    "            \"singular_values\": singular_values,\n",
    "            \"embedding_dimension\": d_hat,\n",
    "            \"modularity\": modularity,\n",
    "            \"assortativity\": assortativity,\n",
    "            \"density\": density,\n",
    "            \"clustering_coefficient\": clustering_coefficient\n",
    "        }\n",
    "        print(f\"Embedding Dimension {year}: {d_hat}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd-polarization-python-KT6HSxR2-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
